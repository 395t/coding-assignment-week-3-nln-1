{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    },
    "colab": {
      "name": "Nonlinear_Activation_and_Initalizations.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XiDWmkBv_NCQ"
      },
      "source": [
        "# Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7HFuKCK_LHd"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# training config\n",
        "NUM_EPOCHS=1\n",
        "VALID_FREQ=1   # Number of epochs between calculating validation set metrics\n",
        "INIT_TYPE_LIST=['default', 'normalized', 'orthogonal', 'xavier']  #Supposed initalization schemes: ['default', 'normalized', 'orthogonal', 'xavier']\n",
        "ACTIVATION_TYPE_LIST=['relu', 'leaky_relu', 'sigmoid', 'tanh', 'softplus', 'softsign', 'maxout'] #Supported activation functions ['relu', 'leaky_relu', 'sigmoid', 'tanh', 'softplus', 'softsign', 'maxout']\n",
        "criterion = nn.CrossEntropyLoss() # Loss function for network training\n",
        "LR=0.001\n",
        "\n",
        "# dataset config\n",
        "batch_size = 4\n",
        "generator=torch.Generator().manual_seed(42) # Can be included for reproducability\n",
        "dataset_name = 'tiny-imagenet'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfp5B4ijmTB4"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnR2yUDo9krx"
      },
      "source": [
        "Using Cuda Device"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iABJF7Rw85y2"
      },
      "source": [
        "# Get cpu or gpu device for training.\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using {} device\".format(device))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNHZVvI7mTB7"
      },
      "source": [
        "# Load Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRDLDLo7mTB8"
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "if dataset_name == 'CIFAR-10':\n",
        "  NUM_CLASSES=10\n",
        "\n",
        "  trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "  testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                        download=True, transform=transform)\n",
        "  \n",
        "\n",
        "  trainset, validset = torch.utils.data.random_split(trainset, \n",
        "                                                    [int(len(trainset)*0.8),len(trainset)- \n",
        "                                                     int(len(trainset)*0.8)], generator=generator)\n",
        "  \n",
        "elif dataset_name == 'tiny-imagenet':\n",
        "  NUM_CLASSES=200\n",
        "  \n",
        "  !wget http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
        "  !unzip -qq 'tiny-imagenet-200.zip'\n",
        "  \n",
        "  \n",
        "  totalset = torchvision.datasets.ImageFolder('tiny-imagenet-200/train', \n",
        "                                                   transform=transform)\n",
        "  \n",
        "  train_counts = [0] * 200\n",
        "  valid_counts = [0] * 200\n",
        "  trainset = []\n",
        "  validset = []\n",
        "  testset = []\n",
        "  for item in totalset:\n",
        "    if train_counts[item[1]] < 350:\n",
        "      trainset.append(item)\n",
        "      train_counts[item[1]] += 1\n",
        "    elif valid_counts[item[1]] < 75:\n",
        "      validset.append(item)\n",
        "      valid_counts[item[1]] += 1\n",
        "    else:\n",
        "      testset.append(item)\n",
        "\n",
        "elif dataset_name == 'Caltech101':\n",
        "  NUM_CLASSES=101\n",
        "  !gdown https://drive.google.com/uc?id=1DX_XeKHn3yXtZ18DD7qc1wf-Jy5lnhD5\n",
        "  !unzip -qq '101_ObjectCategories.zip' \n",
        "\n",
        "  PATH = '101_ObjectCategories/'\n",
        "\n",
        "  transform = transforms.Compose(\n",
        "    [transforms.CenterCrop(256),\n",
        "     transforms.Resize((64,64)),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "  \n",
        "  totalset = torchvision.datasets.ImageFolder(PATH, transform=transform)\n",
        "\n",
        "  X, y = zip(*totalset)\n",
        "\n",
        "  X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.3, \n",
        "                                                    stratify=y)\n",
        "  X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, \n",
        "                                                  test_size = 0.5, \n",
        "                                                  stratify=y_val)\n",
        "\n",
        "  trainset, validset, testset = list(zip(X_train, y_train)), list(zip(X_val, y_val)), list(zip(X_test, y_test))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "validloader = torch.utils.data.DataLoader(validset, batch_size=batch_size,\n",
        "                                          shuffle=False,num_workers=2)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKYnNypdmTCB"
      },
      "source": [
        "# Network Architecture\n",
        "#### On CIFAR-10, we use the 'Net' class, which is the base structure for our experiments.\n",
        "#### For tiny-imagenet and Caltech101, we use 'Net64', so that we could process 64x64 images.\n",
        "#### The main difference lies in the numbers of nodes in the fully connected layers; Net64 contains more neurons in the FC layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbJAab7KmTCE"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    # Helper functions so that the other activation functions \n",
        "    # have the same format as maxout\n",
        "    def relu(self, x, layers):\n",
        "        return F.relu(layers[0](x))\n",
        "\n",
        "    def leaky_relu(self, x, layers):\n",
        "        return F.leaky_relu(layers[0](x))\n",
        "\n",
        "    def sigmoid(self, x, layers):\n",
        "        return F.sigmoid(layers[0](x))\n",
        "\n",
        "    def tanh(self, x, layers):\n",
        "        return F.tanh(layers[0](x))\n",
        "\n",
        "    def softsign(self, x, layers):\n",
        "        return F.softsign(layers[0](x))\n",
        "\n",
        "    def softplus(self, x, layers):\n",
        "        return F.softplus(layers[0](x))\n",
        "\n",
        "    def maxout(self, x, layers):\n",
        "        max_output = layers[0](x)\n",
        "        for layer in layers[1:]:\n",
        "            max_output = torch.maximum(max_output, layer(x))\n",
        "        return max_output\n",
        "\n",
        "    def __init__(self, num_classes=10, activation_type='relu'):\n",
        "        super().__init__()\n",
        "        self.activation_type = activation_type\n",
        "        maxout_num_units = 1\n",
        "\n",
        "        if self.activation_type == 'relu':\n",
        "            self.activation = self.relu\n",
        "        elif self.activation_type == 'leaky_relu':\n",
        "            self.activation = self.leaky_relu\n",
        "        elif self.activation_type == 'sigmoid':\n",
        "            self.activation = self.sigmoid\n",
        "        elif self.activation_type == 'tanh':\n",
        "            self.activation = self.tanh\n",
        "        elif self.activation_type == 'softsign':\n",
        "            self.activation = self.softsign\n",
        "        elif self.activation_type == 'softplus':\n",
        "            self.activation = self.softplus\n",
        "        elif self.activation_type == 'maxout':\n",
        "            maxout_num_units = 2\n",
        "            self.activation = self.maxout\n",
        "\n",
        "        self.convs1 = nn.ModuleList()\n",
        "        self.convs2 = nn.ModuleList()\n",
        "        self.convs3 = nn.ModuleList()\n",
        "        self.convs4 = nn.ModuleList()\n",
        "\n",
        "        self.fcs1 = nn.ModuleList()\n",
        "        self.fcs2 = nn.ModuleList()\n",
        "\n",
        "        for _ in range(maxout_num_units):\n",
        "            self.convs1.append(nn.Conv2d(3, 8, 5, padding=\"same\"))\n",
        "            self.convs2.append(nn.Conv2d(8, 8, 5, padding=\"same\"))\n",
        "            self.convs3.append(nn.Conv2d(8, 16, 3, padding=\"same\"))\n",
        "            self.convs4.append(nn.Conv2d(16, 16, 3, padding=\"same\"))\n",
        "\n",
        "            self.fcs1.append(nn.Linear(16 * 8 * 8, 480))\n",
        "            self.fcs2.append(nn.Linear(480, 320))\n",
        "\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc3 = nn.Linear(320, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.activation(x, self.convs1)\n",
        "        x = self.pool(self.activation(x, self.convs2))\n",
        "        x = self.activation(x, self.convs3)\n",
        "        x = self.pool(self.activation(x, self.convs4))\n",
        "\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        \n",
        "        x = F.dropout(self.activation(x, self.fcs1), training=self.training)\n",
        "        x = F.dropout(self.activation(x, self.fcs2), training=self.training)\n",
        "        x = self.fc3(x)\n",
        "          \n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6_FffaFjEh1"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Net64(nn.Module):\n",
        "    # Helper functions so that the other activation functions \n",
        "    # have the same format as maxout\n",
        "    def relu(self, x, layers):\n",
        "        return F.relu(layers[0](x))\n",
        "\n",
        "    def leaky_relu(self, x, layers):\n",
        "        return F.leaky_relu(layers[0](x))\n",
        "\n",
        "    def sigmoid(self, x, layers):\n",
        "        return F.sigmoid(layers[0](x))\n",
        "\n",
        "    def tanh(self, x, layers):\n",
        "        return F.tanh(layers[0](x))\n",
        "\n",
        "    def softsign(self, x, layers):\n",
        "        return F.softsign(layers[0](x))\n",
        "\n",
        "    def softplus(self, x, layers):\n",
        "        return F.softplus(layers[0](x))\n",
        "\n",
        "    def maxout(self, x, layers):\n",
        "        max_output = layers[0](x)\n",
        "        for layer in layers[1:]:\n",
        "            max_output = torch.maximum(max_output, layer(x))\n",
        "        return max_output\n",
        "\n",
        "    def __init__(self, num_classes=10, activation_type='relu'):\n",
        "        super().__init__()\n",
        "        self.activation_type = activation_type\n",
        "        maxout_num_units = 1\n",
        "\n",
        "        if self.activation_type == 'relu':\n",
        "            self.activation = self.relu\n",
        "        elif self.activation_type == 'leaky_relu':\n",
        "            self.activation = self.leaky_relu\n",
        "        elif self.activation_type == 'sigmoid':\n",
        "            self.activation = self.sigmoid\n",
        "        elif self.activation_type == 'tanh':\n",
        "            self.activation = self.tanh\n",
        "        elif self.activation_type == 'softsign':\n",
        "            self.activation = self.softsign\n",
        "        elif self.activation_type == 'softplus':\n",
        "            self.activation = self.softplus\n",
        "        elif self.activation_type == 'maxout':\n",
        "            maxout_num_units = 2\n",
        "            self.activation = self.maxout\n",
        "\n",
        "        self.convs1 = nn.ModuleList()\n",
        "        self.convs2 = nn.ModuleList()\n",
        "        self.convs3 = nn.ModuleList()\n",
        "        self.convs4 = nn.ModuleList()\n",
        "\n",
        "        self.fcs1 = nn.ModuleList()\n",
        "        self.fcs2 = nn.ModuleList()\n",
        "\n",
        "        for _ in range(maxout_num_units):\n",
        "            self.convs1.append(nn.Conv2d(3, 8, 5, padding=\"same\"))\n",
        "            self.convs2.append(nn.Conv2d(8, 8, 5, padding=\"same\"))\n",
        "            self.convs3.append(nn.Conv2d(8, 16, 3, padding=\"same\"))\n",
        "            self.convs4.append(nn.Conv2d(16, 16, 3, padding=\"same\"))\n",
        "\n",
        "            self.fcs1.append(nn.Linear(16 * 16 * 16, 960))\n",
        "            self.fcs2.append(nn.Linear(960, 380))\n",
        "\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc3 = nn.Linear(380, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.activation(x, self.convs1)\n",
        "        x = self.pool(self.activation(x, self.convs2))\n",
        "        x = self.activation(x, self.convs3)\n",
        "        x = self.pool(self.activation(x, self.convs4))\n",
        "\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        \n",
        "        x = F.dropout(self.activation(x, self.fcs1), training=self.training)\n",
        "        x = F.dropout(self.activation(x, self.fcs2), training=self.training)\n",
        "        x = self.fc3(x)\n",
        "          \n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cHW095xmTCG"
      },
      "source": [
        "# Initialization methods\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WB6Hq3ZfpDQ-"
      },
      "source": [
        "def init_orthogonal(m):\n",
        "  if isinstance(m, torch.nn.Conv2d) or isinstance(m, torch.nn.Linear):\n",
        "    torch.nn.init.orthogonal_(m.weight)\n",
        "\n",
        "def init_normalized(m):\n",
        "  if isinstance(m, torch.nn.Conv2d) or isinstance(m, torch.nn.Linear):\n",
        "    torch.nn.init.normal_(m.weight, 0.0, 0.1)\n",
        "\n",
        "def init_xavier(m):\n",
        "  if isinstance(m, torch.nn.Conv2d) or isinstance(m, torch.nn.Linear):\n",
        "    torch.nn.init.xavier_uniform_(m.weight)\n",
        "    if m.bias is not None:\n",
        "      torch.nn.init.zeros_(m.bias)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3uhi9QWmTCI"
      },
      "source": [
        "# Train methods\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJsaa6LLmTCH"
      },
      "source": [
        "import torch.optim as optim\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import numpy as np\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Us4dKoVmTCK"
      },
      "source": [
        "def train(trainloader, criterion, optimizer, net, num_epochs, valid_freq):\n",
        "  \n",
        "  best_model_wts = copy.deepcopy(net.state_dict())\n",
        "  best_valid_loss = float(\"inf\")\n",
        "  best_epoch = 0\n",
        "\n",
        "  training_loss=[]\n",
        "  validation_loss=[]\n",
        "\n",
        "  for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
        "      epoch_loss = 0.0\n",
        "      running_loss = 0.0\n",
        "      for i, data in enumerate(trainloader, 0):\n",
        "          # get the inputs; data is a list of [inputs, labels]\n",
        "          inputs, labels = data\n",
        "          inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "          # zero the parameter gradients\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          # forward + backward + optimize\n",
        "          outputs = net(inputs)\n",
        "          loss = criterion(outputs, labels)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          # print statistics\n",
        "          running_loss += loss.item()\n",
        "          epoch_loss += loss.item()\n",
        "          if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "              print('Epoch %d, Batch %5d, Batch loss: %.3f' %\n",
        "                    (epoch + 1, i + 1, running_loss / 2000))\n",
        "              running_loss = 0.0\n",
        "      \n",
        "      training_loss.append(epoch_loss/len(trainloader))\n",
        "      print('Epoch %d, Training loss: %.3f' %\n",
        "            (epoch + 1, training_loss[-1]))\n",
        "\n",
        "\n",
        "      if (epoch%valid_freq == 0):\n",
        "        epoch_loss = 0.0\n",
        "\n",
        "        with torch.no_grad():\n",
        "          for data in validloader:\n",
        "              images, labels = data\n",
        "              images, labels = images.to(device), labels.to(device)\n",
        "              # calculate outputs by running images through the network \n",
        "              outputs = net(images)\n",
        "              loss = criterion(outputs, labels)\n",
        "\n",
        "              epoch_loss += loss.item()\n",
        "\n",
        "        validation_loss.append(epoch_loss/len(validloader))\n",
        "        print('Epoch %d, Validation loss: %.3f' %\n",
        "        (epoch + 1, validation_loss[-1]))\n",
        "\n",
        "        if validation_loss[-1] < best_valid_loss:\n",
        "          best_model_wts = copy.deepcopy(net.state_dict())\n",
        "          best_valid_loss = validation_loss[-1]\n",
        "          best_epoch = epoch\n",
        "\n",
        "  print('Finished Training')\n",
        "\n",
        "\n",
        "  net.load_state_dict(best_model_wts)\n",
        "  print(\"model returned at epoch =\", (best_epoch+1))\n",
        "\n",
        "  return training_loss, validation_loss\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIykyQZJ2sEf"
      },
      "source": [
        "\n",
        "for init_type in INIT_TYPE_LIST:\n",
        "  for activation_type in ACTIVATION_TYPE_LIST:\n",
        "    \n",
        "    if dataset_name == 'CIFAR-10':\n",
        "      net = Net(NUM_CLASSES, activation_type)\n",
        "    elif dataset_name == 'tiny-imagenet' or dataset_name == 'Caltech101':\n",
        "      net = Net64(NUM_CLASSES, activation_type)\n",
        "    \n",
        "    optimizer = optim.SGD(net.parameters(), lr=LR, momentum=0.9)\n",
        "    if init_type == 'normalized':\n",
        "      net.apply(init_normalized)\n",
        "    elif init_type == 'orthogonal': \n",
        "      net.apply(init_orthogonal)\n",
        "    elif init_type == 'xavier':\n",
        "      net.apply(init_xavier)\n",
        "    net.to(device)\n",
        "    training_loss, validation_loss = train(trainloader, criterion, optimizer, net, NUM_EPOCHS, VALID_FREQ)\n",
        "\n",
        "    if not os.path.isdir('Results/'+dataset_name+'/'):\n",
        "      os.mkdir('Results/')\n",
        "      os.mkdir('Results/'+dataset_name+'/')\n",
        "\n",
        "    np.save('Results/'+dataset_name+'/training_loss_'+init_type + '_'+activation_type+'.npy', np.array(training_loss))\n",
        "    np.save('Results/'+dataset_name+'/validation_loss_'+init_type + '_'+activation_type+'.npy', np.array(validation_loss))\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(range(1, len(training_loss)+1), training_loss)\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Training loss\")\n",
        "    plt.savefig('Results/'+dataset_name+'/Training_loss_'+init_type + '_'+activation_type+'.png', bbox_inches='tight')\n",
        "    \n",
        "    plt.figure()\n",
        "    plt.plot(range(1, VALID_FREQ*len(validation_loss)+1, VALID_FREQ), validation_loss)\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Validation Loss\")\n",
        "    plt.savefig('Results/'+dataset_name+'/Validation_loss_'+init_type + '_'+activation_type+'.png', bbox_inches='tight')\n",
        "\n",
        "    if not os.path.isdir('Models/'):\n",
        "      os.mkdir('Models/')\n",
        "\n",
        "    torch.save(net.state_dict(), 'Models/'+dataset_name+'_'+init_type + '_'+activation_type+'.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzFH6MTrDiex"
      },
      "source": [
        "\n",
        "# Convergence Plots\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKyPLp5vDPya"
      },
      "source": [
        "## Training Loss\n",
        "\n",
        "plt.figure(1)\n",
        "x_axis = range(1,(NUM_EPOCHS+1))\n",
        "INIT_TYPE = 'default'\n",
        "\n",
        "for activation_type in ACTIVATION_TYPE_LIST:\n",
        "  training_loss = np.load('Results/'+dataset_name+'/training_loss_'+init_type + '_'+activation_type+'.npy')\n",
        "  plt.plot(x_axis, training_loss, label = activation_type, linewidth=2)\n",
        "\n",
        "plt.xlabel('Epoch', fontsize = 13)\n",
        "plt.ylabel('Loss', fontsize = 13)\n",
        "plt.title('Training Loss on '+dataset_name, fontsize = 15)\n",
        "plt.legend(fontsize = 11)\n",
        "plt.savefig(dataset_name+'_'+INIT_TYPE+\"_training_loss.png\", bbox_inches='tight')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83_RW57KF7b7"
      },
      "source": [
        "## Validation Loss\n",
        "\n",
        "plt.figure(2)\n",
        "x_axis = range(1,(NUM_EPOCHS+1))\n",
        "INIT_TYPE = 'default'\n",
        "\n",
        "for activation_type in ACTIVATION_TYPE_LIST:\n",
        "  validation_loss = np.load('Results/'+dataset_name+'/validation_loss_'+init_type + '_'+activation_type+'.npy')\n",
        "  plt.plot(x_axis, validation_loss, label = activation_type, linewidth=2)\n",
        "\n",
        "plt.xlabel('Epoch', fontsize = 13)\n",
        "plt.ylabel('Loss', fontsize = 13)\n",
        "plt.title('Validation Loss on '+dataset_name, fontsize = 15)\n",
        "plt.legend(fontsize = 11)\n",
        "plt.savefig(dataset_name+'_'+INIT_TYPE+\"_validation_loss.png\", bbox_inches='tight')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFiZIKJKmTCX"
      },
      "source": [
        "# Test Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CRHyAlRmTCY"
      },
      "source": [
        "for init_type in INIT_TYPE_LIST:\n",
        "  for activation_type in ACTIVATION_TYPE_LIST:\n",
        "\n",
        "    if dataset_name == 'CIFAR-10':\n",
        "      net = Net(NUM_CLASSES, activation_type)\n",
        "    elif dataset_name == 'tiny-imagenet' or dataset_name == 'Caltech101':\n",
        "      net = Net64(NUM_CLASSES, activation_type)\n",
        "    net.load_state_dict(torch.load('Models/'+dataset_name+'_'+init_type + '_'+activation_type+'.pth'))\n",
        "    net.to(device)\n",
        "    \n",
        "    correct = 0\n",
        "    total = 0\n",
        "    test_loss = 0.0\n",
        "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            # calculate outputs by running images through the network \n",
        "            outputs = net(images)\n",
        "            # the class with the highest energy is what we choose as prediction\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            test_loss += criterion(outputs, labels)\n",
        "\n",
        "    print('Accuracy of the '+ activation_type +' network on the 10000 test images: %.2f %%' % (\n",
        "        100 * correct / total))\n",
        "    \n",
        "    print('Test loss on the 10000 test images: %.2f ' % (\n",
        "      (test_loss/len(testloader))))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}